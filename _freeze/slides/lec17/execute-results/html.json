{
  "hash": "28c8c6316d08472bd80328a4aafe4386",
  "result": {
    "markdown": "---\ntitle: \"Importance sampling\"\nauthor: \"Dr. Alexander Fisher\"\nexecute:\n  warning: true\nformat: \n    revealjs:\n      smaller: true\n---\n\n\n# Announcements\n\n- Reminders:\n  - lab 6 due tomorrow\n  - exam 2 on Friday\n\n. . . \n\n- quiz\n\n## Last time\n\n\n::: {.cell}\n\n:::\n\n\n\n- We considered computing the integral\n\n\n$$\nV = \\int_1^3 x~e^{-\\frac{(x-4)^2}{2}} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}} dx\n$$\n\nHere, $p(x)$ is the standard normal density and \n\n\n$$\nh(x) = I(x \\in (1, 3))~x~e^{-\\frac{(x-4)^2}{2}}\n$$\n\n\n. . . \n\nSo we can view this as $\\mathbb{E}~h(x) \\approx \\frac{1}{N} \\sum_{i=1}^N h(x)$ where $X$ is standard normal.\n\n\n## $p(x)$ off from $h(x)$\n\n- Note: here $h(x) = x~e^{-\\frac{(x-4)^2}{2}} \\frac{1}{\\sqrt{2\\pi}}$ (i.e. I am dropping the indicator function for illustrative purposes)\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec17_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n## Samples not good for $h(x)p(x)$\n\n:::panel-tabset\n\n## plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec17_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n## code\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2)\nhp = function(x) {\n  h(x) * dnorm(x)\n}\n\nN = 50\npoints = data.frame(x = rnorm(N, 0, 1),\n                    y = rep(0, N))\n\nggplot() +\n xlim(-4, 8) +\n  geom_function(fun = hp) +\n  geom_point(data = points, aes(x = x, y = y)) +\n  labs(x = \"x\", y = \"\") +\n  theme_minimal() + \n  labs(title = \"h(x)p(x)\") +\n  stat_function(fun = hp, \n                xlim = c(1,3),\n                geom = \"area\",\n                fill = \"steelblue\", alpha = 0.5)\n```\n:::\n\n:::\n\n## Resulting in large approximation error\n\n::: panel-tabset\n\n## plot\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec17_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n## code\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(magrittr)\nset.seed(2)\nN = 10000\nx = rnorm(N, 0, 1)\n\nh1 = function(x) {\nz = h(x)\nz[x < 1] = 0\nz[x > 3] = 0\n  return(z)\n}\n\nestimate = vector(length = N)\nfor (n in 1:N) {\n  estimate[n] = mean(h1(x[1:n]))\n}\n\nV = data.frame(x = seq(N),\n               y = estimate)\n\nV %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_line() +\n  theme_minimal() +\n  labs(x = \"N\", y = \"sample mean\") +\n  scale_x_continuous(trans='log10')\n```\n:::\n\n\n:::\n\n## A better strategy\n\n- Notice that\n\n\n$$\nV = \\frac{e^{-4}}{\\sqrt{2}}\n\\int_1^3 x \\frac{1}{\\sqrt{2\\pi(1/2)}}\ne^{-\\frac{(x-2)^2}{2(1/2)}}\n$$\n\n- So we can approximate $V$ by\n\n\n$$\n\\frac{e^{-4}}{\\sqrt{2}}~\\frac{1}{N}\\sum_{i = 1}^N X_i~I(X_i\\in(1,3))\n$$\n\n\nwhere $X_i \\overset{\\mathrm{iid}}{\\sim} N(2, (1/\\sqrt{2})^2))$\n\n## Comparison\n\n::: panel-tabset\n\n## Plot\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lec17_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n## Code\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(magrittr)\nset.seed(2)\nN = 10000\nx = rnorm(N, 2, sqrt(1/2))\n\nhnew = function(x) {\nx[x < 1] = 0\nx[x > 3] = 0\n  return(x)\n}\n\nC = exp(-4) / sqrt(2)\n# C = sqrt(1/2)\n\nestimate = vector(length = N)\nfor (n in 1:N) {\n  estimate[n] = mean(hnew(x[1:n]))\n}\n\nestimate = estimate*C\n\nV2 = data.frame(x = seq(N),\n               y = estimate)\n\nV %>%\n  ggplot(aes(x = x, y = y)) +\n  geom_line(aes(color = \"Naive approach\")) +\n  geom_line(data = V2, aes(x = x, y = y, col = \"New sampler\")) +\n  theme_minimal() +\n  labs(x = \"N\", y = \"sample mean\") +\n  scale_x_continuous(trans='log10')\n```\n:::\n\n:::\n\n## Importance sampling identity\n\n- One can always write $V$ as\n\n\n$$\nV = \\int \\frac{h(x)p(x)}{q(x)} q(x) dx\n$$\n\nfor any density $q$ with $q(x) > 0$ on $\\mathcal{X} = \\{x : h(x)p(x) \\neq 0\\}$\n\n. . . \n\n- Thus we can always approximate $V$ by \n\n\n$$\n\\hat{V}_q = \\frac{1}{N} \\sum_{i =1}^N w_q(X_i)h(X_i)\n$$\n\n\nwhere $w_q(x) = p(x) / q(x)$ and $X_i \\overset{\\mathrm{iid}}{\\sim} q$. $w_q(x)$ is called the \"importance weight\".\n\n. . . \n\n- The efficiency of $\\hat{V}_q$ is inversely proportional to its variance:\n\n\n$$\n\\sigma^2_q = \\mathbb{V}ar[\\hat{V}_q] = \\int \\frac{h(x)p(x)}{q(x)}h(x)p(x)dx - V^2\n$$\n\nIf $h > 0$ on $\\mathcal{X}$, then $\\sigma_q^2$ is minimized at $q(x) \\propto h(x)p(x)$.\n\n## Importance sampling recap\n\n- fundamentally, a trick to help compute expectations in Monte Carlo integration.\n\n- the strategy of sampling from $q$ different from $p$ is\ncalled importance sampling.\n\n- $q$ is the \"importance density\".\n- $w_q(X_i)$ is the \"importance weight\" of the sampled $X_i$\n- the optimal $q(x) \\propto h(x)p(x)$ choice is never there â€“ since then\nthe problem becomes trivial!\n- but one tries to choose $q(x)$ such that $\\sigma^2_q$ is small\n\n## Posterior mean example\n\n- Suppose we know $p(x) = \\frac{1}{c} g(x)$ where the functional form $g$ is\nknown but the normalizing constant $c$ is not.\n\n- It is easy to see that $c = \\int h_c(x)p(x)dx$ where\n$h_c(x) = g(x)/p(x)$.\n\n- Therefore, \n\n\n$$\n\\hat{c}_q = \\frac{1}{N} \\sum_{i = 1}^N w_q(X_i) h_c(X_i) = \\frac{1}{N} \\sum_{i = 1}^N w_q^*(X_i)\n$$\n\n\nwhere $w_q^*(x) = g(x) / q(x)$. Notice that \n\n\n$$\nc = \\int g(x) dx = \\int w_q^*(x) q(x) dx = \\mathbb{E_q}[w_q^*]\n$$\n\n\n. . . \n\n- Hence a simulation consistent estimate of $V$ is \n\n\n$$\n\\hat{V}_q = \\frac{\\sum_{i = 1}^N w_q^*(X_i)h(X_i)}{\\sum_{i = 1}^N w_q^*}\n$$\n\n\n## Further reading\n\n- A concise review of importance sampling: [Tokdar, Surya T., and Robert E. Kass. \"Importance sampling: a review.\" Wiley Interdisciplinary Reviews: Computational Statistics 2.1 (2010): 54-60.](https://www2.stat.duke.edu/~st118/Publication/impsamp.pdf)\n\n- A natural extension to handle multi-modality: [Neal, Radford M. \"Annealed importance sampling.\" Statistics and computing 11 (2001): 125-139.](https://link.springer.com/article/10.1023/A:1008923215028)\n\n- [Blog post by Radford Neal on \"The harmonic mean of the likelihood: worst Monte Carlo method ever\"](https://radfordneal.wordpress.com/2008/08/17/the-harmonic-mean-of-the-likelihood-worst-monte-carlo-method-ever/)\n\n- Alternative introduction with some motivation: [Bugallo, Monica F., et al. \"Adaptive importance sampling: The past, the present, and the future.\" IEEE Signal Processing Magazine 34.4 (2017): 60-79.](https://ieeexplore.ieee.org/abstract/document/7974876)\n\n## Acknowledgements\n\nThe best parts of these slides were adapted from Prof. Surya Tokdar's notes on Monte Carlo integration.\n",
    "supporting": [
      "lec17_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}