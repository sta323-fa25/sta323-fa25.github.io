{
  "hash": "e5e0bb320450a839c9414f2d6774d053",
  "result": {
    "markdown": "---\ntitle: \"Intro to optimization\"\nauthor: \"Dr. Alexander Fisher\"\nexecute:\n  warning: true\nformat: \n    revealjs:\n      smaller: true\n---\n\n\n# \n\n![](images/euler.png){fig-align=\"center\"}\n\n> \"...nothing at all takes place in the universe in which some rule of maximum or minimum does not appear.\" Leonhard Euler\n\n## Motivation\n\n\n::: {.cell}\n\n:::\n\n\nIn statistics, common themes for optimization include\n\n-   Maximum likelihood estimate (MLE)\n-   Maximum a posterior probability (MAP) estimate\n-   Minimize a loss function, e.g. least squares, least absolute value regression, multi-dimensional scaling, KL-divergence etc.\n\n# Background: likelihoods\n\n## Example: normal likelihood\n\nLet $X$ be the resting heart rate (RHR) in beats per minute of a student in this class.\n\nAssume RHR is normally distributed with some mean $\\mu$ and standard deviation $8$.\n\n. . .\n\n\n$$\n\\textbf{Data-generative model: } X_i \\overset{\\mathrm{iid}}{\\sim} N(\\mu, 64)\n$$\n\n. . .\n\nIf we observe three student heart rates, {75, 58, 68} then our likelihood \n\n$$L(\\mu) = f_x(75 |\\mu) \\cdot f_x(58|\\mu) \\cdot f_x(68|\\mu).$$\n\nThat is, the joint density function of the observed data as a function of the parameter.\n\n. . . \n\n::: callout-important\nThe likelihood itself is **not a density function**.\n:::\n\n## Visualizing the likelihood\n\n\n$$L(\\mu) = f_x(75 |\\mu) \\cdot f_x(58|\\mu) \\cdot f_x(68|\\mu).$$\n\n\n::: panel-tabset\n\n### data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx = c(75, 58, 68)\n```\n:::\n\n\n\n### likelihood function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nL = function(mu, x) {\n  stopifnot(is.numeric(x))\n  n = length(x)\n  likelihood = 1\n  for(i in 1:n){\n    likelihood = likelihood * dnorm(x[i], mean = mu, sd = 8)\n  }\n  return(likelihood)\n}\n```\n:::\n\n\n### plot\n\n\n::: {.cell layoutWidth='25'}\n::: {.cell-output-display}\n![](lec11_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n### plot code\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  xlim(c(50, 83)) +\n  geom_function(fun = L, args = list(x = x)) +\n  theme_bw() +\n  labs(x = expression(mu), y = \"likelihood\")\n```\n:::\n\n\n:::\n\n. . . \n\nThe maximum likelihood estimate $\\hat{\\mu} = \\frac{75 + 58 + 68}{3} = 67$.\n\nThe **maximum likelihood estimate** is the parameter value that *maximizes* the likelihood function. \n\n\n::: {.cell}\n\n:::\n\n\n## The log-likelihood\n\nNotice how small the y-axis is on the previous slide. What happens to the scale of the likelihood as we add additional data points?\n\n\n\n$$\nL(\\mu) = \\prod_{i = 1}^{n} f_x(x_i |\\mu)\n$$\n\n\n. . . \n\nSince densities evaluate between 0 and 1, multiplying many together (as we often do in likelihoods) can quickly result in floating point underflow. That is, numbers smaller than the computer can actually represent in memory.\n\n. . .\n\n#### log to the rescue!\n\n- `log` is a monotonic function, i.e. $x > y$ implies $\\log(x) > \\log(y)$, because of this the maximum of $f$ is the same as the maximum of $\\log f$.\n\n- additionally, `log` turns products into sums\n\nin practice, we always work with the log-likelihood,\n\n\n$$\n\\log L(\\mu) = \\sum_{i = 1}^n \\log f_x(x_i | \\mu).\n$$\n\n## Exercise\n\n- Write a function in R that returns the log-likelihood for the previous example without using `dnorm`\n\n- Plot your log-likelihood function.\n\n- Add a red vertical line at $\\mu = \\bar{x}$.\n\n- What's the range of the y-axis?\n\n## How do you maximize/minimize a function?\n\n- If $f$ is differentiable, then maxima/minima will satisfy $Df = 0$. We reduce the problem to \"root-finding\".\n\n- Root-finding: $a$ is said to be a \"root\" or a \"fixed point\" of $f$ if $f(a) = 0$.\n\nIn examples like the previous problem, we can solve analytically. But sometimes, we won't be able to...\n\n## Weibull distribution\n\n- A Weibull distribution is a generalized gamma distribution (a gamma distribution with two shape parameters) where both shape parameters are equal to $k$.\n\nThe Weibull density function,\n\n\n$$\nf_x(x | \\lambda, k) = \\begin{cases}\n\\frac{k}{\\lambda} \\left(\\frac{x}{\\lambda} \\right)^{k-1} e^{-(x/\\lambda)^k} & x >0\\\\\n0 & x <0\n\\end{cases}\n$$\n\n\nwhere $k>0$ is the shape parameter and $\\lambda > 0$ is the scale parameter.\n\nAll the usual R functions:\n\n- `dweibull`\n- `pweibull`\n- `qweibull`\n- `rweibull`\n\n. . . \n\nWhy can't we find MLEs $(\\hat{k}, \\hat{\\lambda})$  analytically?\n\n\n## Gradient of likelihood of n independent Weibull draws\n\nLet $X_i \\sim \\text{Weibull}(\\lambda, k)$ and we have $n$ samples: $x = \\{x_1, \\ldots, x_n\\}$.\n\n\n$$\n\\begin{aligned}\n\\log L(\\lambda, k) &= \\sum_{i = 1}^{n} \\log f_x(x_i |\\lambda, k)\\\\\n&= \\sum_{i=1}^n \\log \\frac{k}{\\lambda} + (k-1) \\log \\frac{x_i}{\\lambda} - \\left(\\frac{x_i}{\\lambda} \\right)^k\n\\end{aligned}\n$$\n\n. . .\n\n\n$$\n\\frac{\\partial}{\\partial \\lambda} \\log L(\\lambda, k) = 0 \\implies\\\\\n\\hat{\\lambda} = \\left(\\frac{\\sum_{i = 1}^n (x_i^k)}{n}\\right)^{1/k}\n$$\n\n\n. . . \n\nSetting\n\n\n$$\n\\frac{\\partial}{\\partial k} \\log L(\\lambda, k) = 0,\n$$\n\n\nand plugging in $\\hat{\\lambda}$ from above implies $\\hat{k}$ is the value of $k$ that satisfies\n\n\n$$\n\\frac{\\sum_{i = 1}^n x_i^k \\log x_i}{\\sum_{i = 1}^n x_i^k} - \\frac{1}{k} - \\frac{1}{n} \\sum_{i=1}^n \\log x_i = 0\n$$\n\n# Root finding\n\n## univariate Newton-Raphson\n\n-   If $a$ satisfies $f(a) = 0$, $a$ is said to be a \"fixed point\" or \"root\" of the function\n-   Newton-Raphson is a \"root-finding\" method\n-   Based on first order approximation of a function, $\\ f(a) \\approx f(x) + f'(x)(a - x)$\n\nNear fixed points, the first order approximation is: \n\n\n$$\n0 \\approx f(x) + f'(x)(a - x).\n$$\n\n\nWe are trying to find $a$, so if $f'(x)$ invertible, we rearrange\n\n\n$$\na = x - \\frac{f(x)}{f'(x)}\n$$\n\n\n. . .\n\nand the procedural update is\n\n\n$$\nx_{n+1} = x_n - \\frac{f(x)}{f'(x)}\n$$\n\n\n## Code example\n\nIn practice, we tolerate close solutions, i.e. $a$ such that $f(a) \\approx 0$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnewton = function(f, fp, x, tol) {\n  for (i in 1:100) {\n    x = x - f(x) / fp(x)\n    if (abs(f(x)) < tol) {\n      return(x)\n    }\n  }\n  return(x)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nf = function(x) {\n  return(x ^ 3 - 5 * x + 1)\n}\n\nfp = function(x) {\n  return(3 * x ^ 2 - 5.0)\n}\nnewton(f, fp, 0.0, 1e-14)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2016397\n```\n:::\n:::\n\n\n## Exercise\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx = c(1.470695, 0.3575424, 0.9695413, 1.075623, 0.6361029,\n      0.6329211, 1.630696, 1.143087, 0.6703566, 0.5963144,\n      0.765227, 0.7756703, 0.7327915, 0.699267, 0.2717423,\n      0.3266376, 1.688557, 0.4979863, 0.2270031, 1.175155)\n```\n:::\n\n\n- Find the maximum likelihood estimates $\\hat{k}$ and $\\hat{\\lambda}$ using Newton's method.\n",
    "supporting": [
      "lec11_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}