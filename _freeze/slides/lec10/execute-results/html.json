{
  "hash": "418f2ce76953348db690879111047ad6",
  "result": {
    "markdown": "---\ntitle: \"Complexity and parallelization\"\nauthor: \"Dr. Alexander Fisher\"\nexecute:\n  warning: true\nformat: \n    revealjs:\n      smaller: true\n---\n\n\n# Computational complexity\n\n## Measuring efficiency\n\n**flops** or floating point operations measure the efficiency of an algorithm. **flops** consist of the binary floating point operations: addition, subtraction, multiplication, division and comparison. Individual floating point operations are performed by a single \"core\" of your computer's CPU or GPU.\n\nWe use \"big O\" $\\mathcal{O}(n)$ notation to denote the complexity of an algorithm. For example,\n\n-   matrix-vector multiplication `A %*% b`, where $A$ is $m \\times n$ and $b$ is $n \\times 1$ takes $2mn$ or $\\mathcal{O}(mn)$ flops.\n\n-   matrix-matrix multiplication `A %*% B`, where $A$ is $m \\times n$ and $B$ is $n \\times p$ takes $2mnp$ or $\\mathcal{O}(mnp)$ flops.\n\nNotice that in reporting complexity of each example we drop the leading constant \"2\".\n\nA hierarchy of computational complexity (let $n$ be the problem size):\\\n\\\n\n|                                       |                    |\n|---------------------------------------|--------------------|\n| exponential order: $\\mathcal{O}(b^n)$ | NP-hard (horrible) |\n| polynomial order: $\\mathcal{O}(n^q)$  | doable             |\n| $\\mathcal{O}(n \\log n)$               | fast               |\n| linear order: $\\mathcal{O}(n)$        | fast               |\n| log order: $\\mathcal{O}(\\log n)$      | super fast         |\n\n::: callout-note\nSome references count multiplication followed by an addition (fused multiply-add, FMA) as one flop.\n:::\n\n\\small{This slide adapted from [notes](http://hua-zhou.github.io/teaching/biostatm280-2019spring/slides/05-algo/algo.html) by Dr. Hua Zhou}\n\n## Measuring efficiency (example)\n\nSuppose you wish to calculate a likelihood $L(x|\\theta)$ for $n$ iid observations: $x = \\{x_i\\}; i \\in \\{1, \\ldots, n \\}$. The likelihood looks like\n\n\n$$\nL(x|\\theta) = \\prod_i^n f(x_i | \\theta)\n$$ where $f$ is some density function dependent on parameters $\\theta$.\n\n\n$L(x|\\theta)$ has $\\mathcal{O}(n)$ complexity, i.e. scales linearly with the number of data points.\n\n# Benchmarking\n\n## `bench`\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd = tibble(\n  x = runif(10000),\n  y=runif(10000)\n)\n(b = bench::mark(\n  d[d$x > 0.5, ],\n  d[which(d$x > 0.5), ],\n  subset(d, x > 0.5),\n  filter(d, x > 0.5)\n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 6\n  expression                 min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>            <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 d[d$x > 0.5, ]        102.92µs 116.71µs     7998.  252.16KB     21.7\n2 d[which(d$x > 0.5), ]  88.08µs     99µs     9353.   271.9KB     51.1\n3 subset(d, x > 0.5)    145.17µs 160.38µs     5938.   288.2KB     35.0\n4 filter(d, x > 0.5)      2.05ms   2.15ms      454.    2.01MB     12.7\n```\n:::\n:::\n\n\n## `bench` - relative results\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(b, relative = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 6\n  expression              min median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>            <dbl>  <dbl>     <dbl>     <dbl>    <dbl>\n1 d[d$x > 0.5, ]         1.17   1.18      17.6      1        1.71\n2 d[which(d$x > 0.5), ]  1      1         20.6      1.08     4.03\n3 subset(d, x > 0.5)     1.65   1.62      13.1      1.14     2.76\n4 filter(d, x > 0.5)    23.2   21.7        1        8.17     1   \n```\n:::\n:::\n\n\n# Parallelization\n\n## What is parallelization?\n\n-   \"parallelization\" or \"parallel computing\" means deploying an algorithm's calculations across several cores of a computer to perform computation at the same time\n\n### Terminology\n\n-   CPU: central processing unit, primary component of a computer that processes instructions\n\n-   Core: an individual processor within a CPU, more cores can improve performance and efficiency\n\n-   Forking: a copy of the current R session is moved to new cores.\n\n    -   Not available on Windows\n    -   Less overhead and easy to implement\n\n-   Sockets: a new R session is launched on each core.\n\n    -   Available on all systems\n    -   Each process on each core is unique\n\n## Package `parallel`\n\n-   base R package\n\n-   tools for the forking of R processes (some functions do not work on Windows)\n\n-   Core functions:\n\n    -   `detectCores`\n    -   `pvec`\n    -   `mclapply`\n    -   `mcparallel` & `mccollect`\n\n## pvec\n\nParallelization of a vectorized function call. Forking takes time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parallel)\nsystem.time(pvec(1:1e7, sqrt, mc.cores = 1))\n\n## user  system elapsed \n## 0.031   0.032   0.063 \n\nsystem.time(pvec(1:1e7, sqrt, mc.cores = 4))\n\n## user  system elapsed \n## 0.249   0.197   0.323 \n\nsystem.time(pvec(1:1e7, sqrt, mc.cores = 8))\n\n## user  system elapsed \n## 0.156   0.225   0.204 \n```\n:::\n\n\n-   `?proc.time` for info\n\n-   **User CPU time**: the CPU time spent by the current process, in our case, the R session\n\n-   **System CPU time**: the CPU time spent by the OS on behalf of the current running process\n\nNote that the *wall time* may be the less than the sum total (user + system) since parallelized processes accumulate user/system time at the same time.\n\n## pvec - `bench::system_time`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(bench)\nsystem_time(pvec(1:1e7, sqrt, mc.cores = 1))\n\n## process    real \n## 83.5ms  83.2ms \n\nsystem_time(pvec(1:1e7, sqrt, mc.cores = 4))\n\n## process    real \n## 266ms   312ms \n\nsystem_time(pvec(1:1e7, sqrt, mc.cores = 8))\n\n## process    real \n## 249ms   262ms\n```\n:::\n\n\n## `mclapply`\n\n-   Parallelized `lapply`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time(rnorm(1e6))\n\n## user  system elapsed \n## 0.047   0.004   0.051 \n\nsystem.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 2)))\n\n## user  system elapsed \n## 0.055   0.032   0.049 \n\nsystem.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 4)))\n\n## user  system elapsed \n## 0.058   0.039   0.036 \n```\n:::\n\n\n## `mclapply`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 8)))\n\n## user  system elapsed \n## 0.064   0.068   0.039 \n\nsystem.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 10)))\n\n## user  system elapsed \n## 0.068   0.084   0.046 \n\nsystem.time(unlist(mclapply(1:10, function(x) rnorm(1e5), mc.cores = 12)))\n\n## user  system elapsed \n## 0.067   0.078   0.045 \n```\n:::\n\n\n## `mcparallel`\n\nAsynchronously evaluation of an R expression in a separate process\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm = mcparallel(rnorm(1e6))\nn = mcparallel(rbeta(1e6,1,1))\no = mcparallel(rgamma(1e6,1,1))\n\nstr(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 2\n $ pid: int 12106\n $ fd : int [1:2] 4 7\n - attr(*, \"class\")= chr [1:3] \"parallelJob\" \"childProcess\" \"process\"\n```\n:::\n\n```{.r .cell-code}\nstr(n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 2\n $ pid: int 12107\n $ fd : int [1:2] 5 9\n - attr(*, \"class\")= chr [1:3] \"parallelJob\" \"childProcess\" \"process\"\n```\n:::\n:::\n\n\n## `mccollect`\n\nChecks `mcparallel` objects for completion\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(mccollect(list(m,n,o)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 3\n $ 12106: num [1:1000000] 1.62 0.904 -1.865 -2.384 -0.16 ...\n $ 12107: num [1:1000000] 0.224 0.241 0.733 0.532 0.129 ...\n $ 12108: num [1:1000000] 0.2199 0.0562 0.3705 0.998 6.7013 ...\n```\n:::\n:::\n\n\n. . .\n\n#### mccollect - waiting\n\n\n::: {.cell}\n\n```{.r .cell-code}\np = mcparallel(mean(rnorm(1e5)))\nmccollect(p, wait = FALSE, 10) # will retrieve the result (since it's fast)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$`12109`\n[1] 0.001003654\n```\n:::\n\n```{.r .cell-code}\nmccollect(p, wait = FALSE) # will signal the job as terminating\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in selectChildren(jobs, timeout): cannot wait for child 12109 as it does\nnot exist\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n:::\n\n\n# doMC & foreach\n\n## doMC & foreach\n\nPackages by Revolution Analytics that provides the `foreach` function which is a parallelizable for loop.\n\nPackage `doMC` is a parallel backend for the `foreach` package - a package that allows you to execute for loops in parallel.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(doMC)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: foreach\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'foreach'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:purrr':\n\n    accumulate, when\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: iterators\n```\n:::\n:::\n\n\nCore functions:\n\n-   `doMC::registerDoMC` sets the number of cores for the parallel backend to be used with foreach\n\n-   `foreach`, `%dopar%`, `%do%`\n\n`doMC` serves as an interface between `foreach` and `parallel` Since `parallel` only works with systems that support forking, these functions will not work properly on Windows.\n\n## Set workers\n\nTo get started, set the number of cores with `registerDoMC()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check cores set up\ngetDoParWorkers()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n\n```{.r .cell-code}\n# set 4 cores\nregisterDoMC(4)\ngetDoParWorkers()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4\n```\n:::\n:::\n\n\n## Serial and parallel with foreach()\n\n::: columns\n::: {.column width=\"50%\"}\n#### Sequential\n\n-   `%do%` single execution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforeach(i = 1:4) %do% \n  sort(runif(n = 1e7, max = i))[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 1.653098e-08\n\n[[2]]\n[1] 1.634471e-07\n\n[[3]]\n[1] 2.214219e-07\n\n[[4]]\n[1] 2.998859e-07\n```\n:::\n\n```{.r .cell-code}\ntimes(2) %do%\n  sort(runif(n = 1e7))[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.515727e-07 8.847564e-09\n```\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n#### Parallel\n\n-   `%dopar%` multicore execution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforeach(i = 1:4) %dopar%\n  sort(runif(n = 1e7, max = i))[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 1.001172e-08\n\n[[2]]\n[1] 1.653098e-07\n\n[[3]]\n[1] 5.587935e-09\n\n[[4]]\n[1] 1.529232e-06\n```\n:::\n\n```{.r .cell-code}\ntimes(2) %dopar%\n  sort(runif(n = 1e7))[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.444722e-08 1.024455e-08\n```\n:::\n:::\n\n:::\n:::\n\n## Time comparison\n\n::: columns\n::: {.column width=\"50%\"}\n#### Sequential\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time({\nforeach(i = 1:4) %do% \n  sort(runif(n = 1e7, max = i))[1]\n\ntimes(2) %do%\n  sort(runif(n = 1e7))[1]\n})\n\n##  user  system elapsed \n## 3.371   0.143   3.507 \n```\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n#### Parallel\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time({\nforeach(i = 1:4) %dopar% \n  sort(runif(n = 1e7, max = i))[1]\n\ntimes(2) %dopar%\n  sort(runif(n = 1e7))[1]\n})\n\n##  user  system elapsed \n## 2.917   0.603   1.376 \n```\n:::\n\n:::\n:::\n\n## Things to know about `foreach`\n\n`foreach` can iterate across more than one value, but it doesn't do length coercion.\n\n::: columns\n::: {.column width=\"50%\"}\nNote: `foreach` is iterating over both simultaneously. This is *not* a nested for loop.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforeach(i = 1:3, j = 1:3) %do% {\n  sqrt(i^2+j^2)   \n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 1.414214\n\n[[2]]\n[1] 2.828427\n\n[[3]]\n[1] 4.242641\n```\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nNote: `foreach` coerces the longer vector to be shorter!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforeach(i = 1:5, j = 1:2) %do% {\n  sqrt(i^2+j^2)   \n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 1.414214\n\n[[2]]\n[1] 2.828427\n```\n:::\n:::\n\n:::\n:::\n\n## `foreach` bookkeeping\n\n-   `foreach` does some bookkeeping for you and returns a list by default. Compare this to the traditional for loop that does no bookkeeping.\n\n-   you can easily customize the bookkeeping.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforeach(i = 1:5, .combine='c') %do% {\n  sqrt(i)\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.000000 1.414214 1.732051 2.000000 2.236068\n```\n:::\n\n```{.r .cell-code}\nforeach(i = 1:5, .combine='cbind') %do% {\n  sqrt(i)\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     result.1 result.2 result.3 result.4 result.5\n[1,]        1 1.414214 1.732051        2 2.236068\n```\n:::\n\n```{.r .cell-code}\nforeach(i = 1:5, .combine='+') %do% {\n  sqrt(i)\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 8.382332\n```\n:::\n:::\n\n\n## nested `foreach`\n\n-   The `%:%` operator is the nesting operator, used for creating nested foreach loops.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforeach(i = 1:4, .combine = \"c\") %:% \n  foreach(j = 0:1, .combine = \"c\") %dopar% \n    {i ^ j}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 1 1 2 1 3 1 4\n```\n:::\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforeach(i = 1:4, .combine = \"data.frame\") %:% \n  foreach(j = 0:1, .combine = \"c\") %dopar% \n    {i ^ j}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  result.1 result.2 result.3 result.4\n1        1        1        1        1\n2        1        2        3        4\n```\n:::\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforeach(i = 1:4, .combine = \"c\") %:% \n  foreach(j = 0:1, .combine = \"+\") %dopar% \n    {i ^ j}\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 3 4 5\n```\n:::\n:::\n\n\n# furrr\n\n## `future`\n\nA \"future\" is an abstraction for a value that may be available at some point in the future.\n\nThe purpose of the `future` package is to provide a very simple and uniform way of evaluating R expressions asynchronously using various resources available to the user.\n\n-   See [the CRAN `future` documentation](https://cran.r-project.org/web/packages/future/vignettes/future-1-overview.html) for further reading.\n\n## furrr and purrr\n\n- `furrr` functions are just like `purrr` functions but begin with `future_`\n\n#### Example\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(furrr)\nlibrary(tidyverse)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmap_dbl(mtcars, mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mpg        cyl       disp         hp       drat         wt       qsec \n 20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750 \n        vs         am       gear       carb \n  0.437500   0.406250   3.687500   2.812500 \n```\n:::\n\n```{.r .cell-code}\nfuture_map_dbl(mtcars, mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mpg        cyl       disp         hp       drat         wt       qsec \n 20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750 \n        vs         am       gear       carb \n  0.437500   0.406250   3.687500   2.812500 \n```\n:::\n:::\n\n\n##\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession, workers = 8)\nfuture_map_dbl(mtcars, mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mpg        cyl       disp         hp       drat         wt       qsec \n 20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750 \n        vs         am       gear       carb \n  0.437500   0.406250   3.687500   2.812500 \n```\n:::\n:::\n\n\n. . .\n\nNot sure we are running in parallel?\n\n. . . \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time({map_dbl(mtcars, ~ {Sys.sleep(.1); mean(.x)})})\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n  0.004   0.000   1.138 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsystem.time({future_map_dbl(mtcars, ~ {Sys.sleep(.1); mean(.x)})})\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n  0.043   0.002   0.258 \n```\n:::\n:::\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(sequential)\n```\n:::\n\n\n## Example\n\n- How could you parallelize the text mining of lab 4?\n\n- Demo\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}